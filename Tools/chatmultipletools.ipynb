{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eacae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.getenv(\"GROQ_API_KEY\")\n",
    "# GROQ_API_KEY is used to authenticate with the Groq API service.\n",
    "# Make sure to set this environment variable in your .env file or system environment.\n",
    "# Example: export GROQ_API_KEY=\"your_api_key_here\"\n",
    "# For security reasons, do not hardcode sensitive information like API keys directly in your code.\n",
    "# Instead, use environment variables or secure vaults to manage them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0aea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tavily in c:\\users\\adity\\miniconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\adity\\miniconda3\\lib\\site-packages (from tavily) (2.32.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\adity\\miniconda3\\lib\\site-packages (from tavily) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from aiohttp->tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from aiohttp->tavily) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from aiohttp->tavily) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from aiohttp->tavily) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from aiohttp->tavily) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from aiohttp->tavily) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from aiohttp->tavily) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->tavily) (3.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from requests->tavily) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from requests->tavily) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\miniconda3\\lib\\site-packages (from requests->tavily) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "# pip install arxiv\n",
    "# !pip install tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e0ea85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "407023b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper = ArxivAPIWrapper(\n",
    "    top_k_results=2,\n",
    "    document_content_chars_max=500\n",
    ")\n",
    "arxiv = ArxivQueryRun(\n",
    "    api_wrapper=api_wrapper,\n",
    "    description=\"Query arXiv research papers\"\n",
    ")\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b576d92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2022-04-21\\nTitle: Creative Problem Solving in Artificially Intelligent Agents: A Survey and Framework\\nAuthors: Evana Gizzi, Lakshmi Nair, Sonia Chernova, Jivko Sinapov\\nSummary: Creative Problem Solving (CPS) is a sub-area within Artificial Intelligence (AI) that focuses on methods for solving off-nominal, or anomalous problems in autonomous systems. Despite many advancements in planning and learning, resolving novel problems or adapting existing knowledge to a new context, especially in cases where the environment may change in unpredictable ways post deployment, remains a limiting factor in the safe and useful integration of intelligent systems. The emergence of increasingly autonomous systems dictates the necessity for AI agents to deal with environmental uncertainty through creativity. To stimulate further research in CPS, we present a definition and a framework of CPS, which we adopt to categorize existing AI methods in this field. Our framework consists of four main components of a CPS problem, namely, 1) problem formulation, 2) knowledge representation, 3) method of knowledge manipulation, and 4) method of evaluation. We conclude our survey with open research questions, and suggested directions for the future.\\n\\nPublished: 2021-10-05\\nTitle: The Artificial Scientist: Logicist, Emergentist, and Universalist Approaches to Artificial General Intelligence\\nAuthors: Michael Timothy Bennett, Yoshihiro Maruyama\\nSummary: We attempt to define what is necessary to construct an Artificial Scientist, explore and evaluate several approaches to artificial general intelligence (AGI) which may facilitate this, conclude that a unified or hybrid approach is necessary and explore two theories that satisfy this requirement to some degree.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.invoke(\"What are the latest research papers on artificial intelligence?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6521e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f702ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tavily search tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5396bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all together\n",
    "tools=[arxiv,tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63b86e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "# llm.invoke(\"whar is AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6202581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke(\"What is AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e3d6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b993278b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI, or Artificial Intelligence, refers to systems or machines designed to perform tasks that typically require human intelligence. These tasks include learning from experience, reasoning, problem-solving, understanding natural language, recognizing patterns, and making decisions. \\n\\nAI can be categorized into:\\n1. **Narrow AI**: Specialized for specific tasks (e.g., voice assistants like Siri, recommendation algorithms, or image recognition tools).\\n2. **General AI**: A theoretical, human-like intelligence capable of handling any intellectual task (not yet achieved).\\n\\nAI powers technologies like self-driving cars, medical diagnostics, and personalized marketing. It relies on techniques such as machine learning, where systems improve performance through data exposure. While AI enhances efficiency, it also raises ethical questions about bias, privacy, and job displacement.', additional_kwargs={'reasoning_content': 'Okay, the user is asking \"What is AI?\" I need to provide a clear and concise explanation. Let me start by defining AI. Artificial Intelligence, or AI, refers to machines or software designed to perform tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, perception, and language understanding.\\n\\nI should mention the different types of AI, like narrow AI, which is focused on specific tasks, and general AI, which is more versatile but not yet developed. Examples like Siri or Alexa could help illustrate the concept. Also, it\\'s important to note the applications of AI in various fields such as healthcare, finance, and autonomous vehicles. I should avoid technical jargon to keep it accessible. Let me make sure the explanation is comprehensive but not too detailed for a basic understanding.\\n'}, response_metadata={'token_usage': {'completion_tokens': 320, 'prompt_tokens': 254, 'total_tokens': 574, 'completion_time': 0.839660509, 'completion_tokens_details': {'reasoning_tokens': 161}, 'prompt_time': 0.01064155, 'prompt_tokens_details': None, 'queue_time': 0.05170308, 'total_time': 0.850302059}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019befe5-4db7-75e3-963d-95f772b1aeb0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 254, 'output_tokens': 320, 'total_tokens': 574, 'output_token_details': {'reasoning': 161}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"What is AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "599b125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATE SCHEMEA\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage, HumanMessage #human message or ai message, added HumanMessage for initial input\n",
    "from typing import Annotated #labeling\n",
    "from langgraph.graph import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3e53783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages] #list of messages in the chat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0089d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tools_Calling(state:State):\n",
    "    return {\"message\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "# graph\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"tool calling\",tools_Calling)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "#Edges\n",
    "builder.add_edge(START,\"tool calling\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool calling\",\n",
    "    #if the latest message (result) from assistant is a tool call -> tool_condtions routes to took\n",
    "    #if the latest message (result) from assistant is a not a tool call -> tools_condtions routes to END\n",
    "    tools_condition)\n",
    "\n",
    "builder.add_edge(\"tools\",END)\n",
    "graph=builder.compile()\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2d203fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi,What is AI\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "AI, or Artificial Intelligence, refers to systems or machines that demonstrate human-like intelligence. These systems can perform tasks such as learning from experience, understanding natural language, recognizing patterns, solving problems, and making decisions. AI encompasses various subfields, including machine learning, natural language processing, computer vision, and robotics. It is applied in diverse areas like healthcare, finance, transportation, and entertainment to automate processes, enhance efficiency, and provide insights through data analysis. If you'd like, I can provide more specific details or recent advancements in AI using available tools.\n"
     ]
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\": [HumanMessage(content=\"Hi,What is AI\")]}) \n",
    "for msg in messages[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e40c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_10580\\1745773863.py\", line 2, in <module>\n",
      "    s=name[::-1]\n",
      "      ~~~~^^^^^^\n",
      "TypeError: 'int' object is not subscriptable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2176, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "        etype, value, tb, tb_offset=tb_offset\n",
      "    )\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1182, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, etype, evalue, etb, tb_offset, context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1053, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, etype, evalue, etb, tb_offset, context\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 861, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        etype, evalue, etb, context, tb_offset\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 746, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, context, tb_offset) if etb else []\n",
      "              ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 848, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\stack_data\\core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\stack_data\\core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\stack_data\\core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\executing\\executing.py\", line 283, in executing\n",
      "    assert_(new_stmts <= stmts)\n",
      "    ~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\adity\\miniconda3\\Lib\\site-packages\\executing\\executing.py\", line 80, in assert_\n",
      "    raise AssertionError(str(message))\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "name=123345\n",
    "s=name[::-1]\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
